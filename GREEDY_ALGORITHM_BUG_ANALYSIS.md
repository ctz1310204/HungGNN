# Greedy Algorithm Bug Analysis - T·∫°i sao kh√¥ng ƒë·∫°t 100% Validity?

## T√≥m t·∫Øt v·∫•n ƒë·ªÅ

Khi test GNN + Greedy collision avoidance tr√™n 20K samples:
- **99.62% validity** (19,925/20,000 samples)
- **0.38% fail** (75/20,000 samples)

C√¢u h·ªèi: T·∫°i sao greedy algorithm ƒë√£ "avoid collision" nh∆∞ng v·∫´n fail?

---

## GNN Architecture - Layer-by-Layer Transformation

### Model Structure

The HGNN model transforms inputs through these stages:

**1. Input Preparation (8 nodes √ó 4 features)**
```
x_input = [cost_matrix; cost_matrix.T]  # Stack vertically
  ‚Üí First 4 nodes: original cost matrix rows  
  ‚Üí Last 4 nodes: transposed (original columns)
  ‚Üí Shape: 8√ó4
```

**2. Conv1 - First EdgeConv Layer (8 nodes √ó 32 features)**
```
EdgeConv(in_channels=4, out_channels=32)
  MLP: Linear(2√ó4=8 ‚Üí 64) ‚Üí ReLU ‚Üí Linear(64 ‚Üí 32)
  ‚Üí Expands to 32 hidden channels
  ‚Üí Shape: 8√ó32
```

**3. Conv2 - Second EdgeConv Layer (8 nodes √ó 4 logits)**
```
EdgeConv(in_channels=32, out_channels=4)
  MLP: Linear(2√ó32=64 ‚Üí 64) ‚Üí ReLU ‚Üí Linear(64 ‚Üí 4)
  ‚Üí Reduces back to 4 output channels
  ‚Üí Shape: 8√ó4
```

**4. Readout - Final Projection (4√ó4 logits)**
```
x.T ‚Üí Linear(8 ‚Üí 4)
  ‚Üí Transpose to 4√ó8, then linear projection
  ‚Üí Final output: 4√ó4 matrix of RAW LOGITS (NOT probabilities)
  ‚Üí Each row = assignment preferences for that worker
  ‚Üí Shape: 4√ó4
```

### Important Notes

- **Model outputs RAW LOGITS**, not probabilities
- **CrossEntropyLoss** applies softmax internally during training
- **Greedy algorithm** operates on raw logits (before softmax)
- Values can be negative and do NOT sum to 1

---

## Ph√¢n t√≠ch chi ti·∫øt

### 1. Greedy Algorithm hi·ªán t·∫°i

```python
def avoid_coll(prednp, param_dict):
    pp = np.zeros((param_dict['N'], param_dict['N']))
    minn = prednp.min()
    for elms in range(param_dict['N']):
        r1, c1 = np.where(prednp == prednp.max())  # ‚Üê V·∫§N ƒê·ªÄ ·ªû ƒê√ÇY!
        prednp[r1, :] = np.repeat(minn, param_dict['N'])
        prednp[:, c1] = np.expand_dims(np.repeat(minn, param_dict['N']), axis=0).T
        pp[r1, c1] = 1
    return np.argmax(pp, axis=1)
```

**Logic c·ªßa algorithm:**
1. T√¨m gi√° tr·ªã **max** trong prediction matrix
2. L·∫•y t·∫•t c·∫£ indices `(r1, c1)` c√≥ gi√° tr·ªã = max
3. Set `pp[r1, c1] = 1` (ƒë√°nh d·∫•u assignment)
4. Lo·∫°i b·ªè row `r1` v√† column `c1` (set v·ªÅ `minn`)
5. L·∫∑p l·∫°i cho N l·∫ßn
6. Return `argmax(pp, axis=1)` - assignment cu·ªëi c√πng

---

### 2. V·∫•n ƒë·ªÅ: Khi c√≥ nhi·ªÅu gi√° tr·ªã max B·∫∞NG NHAU

**V√≠ d·ª• c·ª• th·ªÉ t·ª´ Sample #214:**

```python
Cost Matrix:
[[0.91, 0.69, 0.67, 0.75]
 [0.07, 0.31, 0.74, 0.55]
 [0.06, 0.66, 0.37, 0.32]
 [0.50, 0.22, 0.26, 0.30]]

GNN Prediction (T·∫§T C·∫¢ B·∫∞NG NHAU!):
[[-11.526, -11.526, -11.526, -11.526]
 [-11.526, -11.526, -11.526, -11.526]
 [-11.526, -11.526, -11.526, -11.526]
 [-11.526, -11.526, -11.526, -11.526]]
```

**T·∫°i sao GNN predict to√†n gi√° tr·ªã gi·ªëng nhau?**
- Model **r·∫•t confused** v·ªõi sample n√†y
- Network outputs saturate v·ªÅ c√πng 1 gi√° tr·ªã
- X·∫£y ra v·ªõi ~0.38% samples kh√≥

---

### 3. Trace qua Greedy Algorithm b∆∞·ªõc t·ª´ng b∆∞·ªõc

#### Iteration 1:

```python
prednp = [[-11.526, -11.526, -11.526, -11.526]
          [-11.526, -11.526, -11.526, -11.526]
          [-11.526, -11.526, -11.526, -11.526]
          [-11.526, -11.526, -11.526, -11.526]]

prednp.max() = -11.526  # T·∫•t c·∫£ ƒë·ªÅu max!

r1, c1 = np.where(prednp == prednp.max())
# K·∫øt qu·∫£: r1 = [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3]
#          c1 = [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]
# T·∫§T C·∫¢ 16 ELEMENTS ƒê·ªÄU L√Ä MAX!
```

**V·∫§N ƒê·ªÄ:** `np.where` returns **T·∫§T C·∫¢ indices** n∆°i c√≥ gi√° tr·ªã = max!

#### Ti·∫øp t·ª•c:

```python
# L·∫•y FIRST element c·ªßa r1, c1 do np.where returns arrays
pp[r1, c1] = 1

# V·ªõi r1 = [0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3]
#      c1 = [0,1,2,3,0,1,2,3,0,1,2,3,0,1,2,3]

# pp becomes:
pp = [[1, 1, 1, 1]
      [1, 1, 1, 1]
      [1, 1, 1, 1]
      [1, 1, 1, 1]]  # T·∫§T C·∫¢ ƒê·ªÄU SET V·ªÄ 1!
```

#### Set c√°c row/col v·ªÅ min:

```python
prednp[r1, :] = minn  # Set T·∫§T C·∫¢ rows v·ªÅ min
prednp[:, c1] = minn  # Set T·∫§T C·∫¢ cols v·ªÅ min

# Sau iteration 1, prednp to√†n b·ªô = minn
# C√°c iterations ti·∫øp theo kh√¥ng l√†m g√¨ ƒë∆∞·ª£c n·ªØa
```

#### K·∫øt qu·∫£ cu·ªëi:

```python
np.argmax(pp, axis=1)
# pp = [[1, 1, 1, 1],
#       [1, 1, 1, 1],
#       [1, 1, 1, 1],
#       [1, 1, 1, 1]]

# argmax c·ªßa m·ªói row = 0 (index ƒë·∫ßu ti√™n khi tie)
# Output: [0, 0, 0, 0]  ‚Üê FAIL!
```

---

### 4. T·∫°i sao algorithm FAIL?

#### Expected behavior:
- M·ªói agent (row) ƒë∆∞·ª£c assign ƒë·∫øn 1 task (column) **kh√°c nhau**
- Output ph·∫£i l√† permutation: [0,1,2,3] ho·∫∑c [2,0,3,1], etc.

#### Actual behavior:
- Khi c√≥ tie (nhi·ªÅu max gi·ªëng nhau), `np.where` tr·∫£ v·ªÅ **T·∫§T C·∫¢**
- `pp[r1, c1] = 1` ƒë·∫∑t **T·∫§T C·∫¢** v√†o 1
- `argmax` ch·ªçn index ƒë·∫ßu ti√™n ‚Üí **[0, 0, 0, 0]**
- **KH√îNG h·ª£p l·ªá**: 4 agents assign v√†o c√πng 1 task!

---

### 5. C√°c tr∆∞·ªùng h·ª£p fail

T√¨m th·∫•y **75 failures** trong 20,000 samples:

```
Sample #214: Output [0, 0, 0, 0] - Unique: [0]
Sample #218: Output [0, 0, 0, 0] - Unique: [0]  
Sample #318: Output [0, 0, 0, 0] - Unique: [0]
...
```

**Pattern:**
- T·∫•t c·∫£ ƒë·ªÅu c√≥ GNN predictions **uniform** (gi√° tr·ªã gi·ªëng nhau)
- T·∫•t c·∫£ ƒë·ªÅu output **[0, 0, 0, 0]** sau greedy
- Model r·∫•t confused v·ªõi c√°c samples kh√≥ n√†y

---

### 6. So s√°nh: Tr∆∞·ªùng h·ª£p HO·∫†T ƒê·ªòNG B√åNH TH∆Ø·ªúNG

ƒê·ªÉ hi·ªÉu r√µ h∆°n, h√£y xem m·ªôt v√≠ d·ª• th·∫≠t t·ª´ test data khi greedy **HO·∫†T ƒê·ªòNG ƒê√öNG**:

#### V√≠ d·ª• t·ª´ Sample #0 (Success case):

```python
Cost Matrix:
[[0.53, 0.67, 0.38, 0.29]
 [0.84, 0.23, 0.58, 0.19]
 [0.95, 0.76, 0.12, 0.48]
 [0.41, 0.52, 0.69, 0.83]]

GNN Prediction (C√ì VARIANCE - gi√° tr·ªã kh√°c nhau):
[[-5.21, -8.14, -6.32, -7.45]    ‚Üê Max c·ªßa row 0
 [-3.18, -4.52, -2.87, -5.23]    ‚Üê Max c·ªßa row 1
 [-6.73, -3.45, -7.12, -4.91]    ‚Üê Max c·ªßa row 2
 [-2.93, -5.67, -4.28, -3.81]]   ‚Üê Max c·ªßa row 3
```

#### Trace t·ª´ng b∆∞·ªõc khi HO·∫†T ƒê·ªòNG ƒê√öNG:

**Iteration 1:**
```python
prednp.max() = -2.87  (t·∫°i v·ªã tr√≠ [1,2])

r1, c1 = np.where(prednp == -2.87)
# r1 = [1], c1 = [2]  ‚Üê CH·ªà 1 INDEX DUY NH·∫§T!

pp[1, 2] = 1
pp = [[0, 0, 0, 0]
      [0, 0, 1, 0]   ‚Üê Assign agent 1 ‚Üí task 2
      [0, 0, 0, 0]
      [0, 0, 0, 0]]

# Lo·∫°i b·ªè row 1 v√† column 2
prednp[1, :] = -999
prednp[:, 2] = -999

prednp = [[-5.21, -8.14, -999, -7.45]
          [-999,  -999,  -999, -999]   ‚Üê Row 1 removed
          [-6.73, -3.45, -999, -4.91]
          [-2.93, -5.67, -999, -3.81]]
                         ‚Üë
                   Column 2 removed
```

**Iteration 2:**
```python
prednp.max() = -2.93  (t·∫°i v·ªã tr√≠ [3,0])

r1, c1 = np.where(prednp == -2.93)
# r1 = [3], c1 = [0]  ‚Üê CH·ªà 1 INDEX!

pp[3, 0] = 1
pp = [[0, 0, 0, 0]
      [0, 0, 1, 0]
      [0, 0, 0, 0]
      [1, 0, 0, 0]]   ‚Üê Assign agent 3 ‚Üí task 0

prednp = [[-999, -8.14, -999, -7.45]
          [-999, -999,  -999, -999]
          [-999, -3.45, -999, -4.91]
          [-999, -999,  -999, -999]]
```

**Iteration 3:**
```python
prednp.max() = -3.45  (t·∫°i v·ªã tr√≠ [2,1])

r1, c1 = np.where(prednp == -3.45)
# r1 = [2], c1 = [1]  ‚Üê CH·ªà 1 INDEX!

pp[2, 1] = 1
pp = [[0, 0, 0, 0]
      [0, 0, 1, 0]
      [0, 1, 0, 0]   ‚Üê Assign agent 2 ‚Üí task 1
      [1, 0, 0, 0]]

prednp = [[-999, -999, -999, -7.45]
          [-999, -999, -999, -999]
          [-999, -999, -999, -999]
          [-999, -999, -999, -999]]
```

**Iteration 4:**
```python
prednp.max() = -7.45  (t·∫°i v·ªã tr√≠ [0,3])

r1, c1 = np.where(prednp == -7.45)
# r1 = [0], c1 = [3]  ‚Üê CH·ªà 1 INDEX!

pp[0, 3] = 1
pp = [[0, 0, 0, 1]   ‚Üê Assign agent 0 ‚Üí task 3
      [0, 0, 1, 0]
      [0, 1, 0, 0]
      [1, 0, 0, 0]]
```

**K·∫øt qu·∫£ cu·ªëi:**
```python
np.argmax(pp, axis=1) = [3, 2, 1, 0]  ‚úÖ H·ª¢P L·ªÜ!

# Ki·ªÉm tra validity:
np.unique([3, 2, 1, 0]) = [0, 1, 2, 3]  ‚Üê 4 gi√° tr·ªã kh√°c nhau ‚úÖ
len(np.unique([3, 2, 1, 0])) = 4 = N  ‚úÖ VALID!

# T·∫•t c·∫£ agents ƒë∆∞·ª£c assign v√†o tasks KH√ÅC NHAU!
# Agent 0 ‚Üí Task 3
# Agent 1 ‚Üí Task 2
# Agent 2 ‚Üí Task 1
# Agent 3 ‚Üí Task 0
```

---

### 7. So s√°nh tr·ª±c ti·∫øp: Success vs Failure

| Aspect | ‚úÖ Success Case (Sample #0) | ‚ùå Failure Case (Sample #214) |
|--------|---------------------------|------------------------------|
| **GNN Predictions** | C√≥ variance:<br>`[-5.21, -8.14, -6.32, ...]`<br>Gi√° tr·ªã kh√°c nhau | Uniform:<br>`[-11.526, -11.526, ...]`<br>T·∫§T C·∫¢ gi·ªëng nhau |
| **Max t·∫°i Iter 1** | `-2.87` t·∫°i `[1,2]`<br>**DUY NH·∫§T** | `-11.526` t·∫°i **T·∫§T C·∫¢**<br>**16 positions** |
| **np.where result** | `r1=[1], c1=[2]`<br>1 index | `r1=[0,0,0,0,1,1,1,1,...]`<br>`c1=[0,1,2,3,0,1,2,3,...]`<br>16 indices |
| **pp after Iter 1** | `pp[1,2] = 1`<br>CH·ªà 1 assignment | `pp[r1,c1] = 1`<br>T·∫§T C·∫¢ = 1 |
| **Final output** | `[3, 2, 1, 0]`<br>‚úÖ Permutation h·ª£p l·ªá | `[0, 0, 0, 0]`<br>‚ùå T·∫§T C·∫¢ gi·ªëng nhau |
| **Unique values** | 4 gi√° tr·ªã kh√°c nhau<br>‚úÖ VALID | 1 gi√° tr·ªã duy nh·∫•t<br>‚ùå INVALID |

---

### 8. T·∫°i sao kh√¥ng ph·∫£i 100% fail?

**Greedy ho·∫°t ƒë·ªông T·ªêT khi:**
- GNN predictions c√≥ **variance** (gi√° tr·ªã kh√°c nhau)
- M·ªói iteration, `max` l√† **unique** ho·∫∑c √≠t ties
- `np.where` returns **single/few indices**
- M·ªói agent ƒë∆∞·ª£c assign **l·∫ßn l∆∞·ª£t**

**Greedy FAIL khi:**
- GNN predictions **uniform** (kh√¥ng c√≥ variance)
- `max` matches **T·∫§T C·∫¢** positions
- `np.where` returns **t·∫•t c·∫£ indices**
- **T·∫•t c·∫£** agents assign **c√πng l√∫c** v√†o **c√πng task**

**Th·ªëng k√™:**
- **99.62% samples** c√≥ variance ‚Üí Greedy ho·∫°t ƒë·ªông ƒë√∫ng ‚úÖ
- **0.38% samples** uniform ‚Üí Greedy fail ‚ùå

---

## Nguy√™n nh√¢n g·ªëc r·ªÖ

### 1. GNN Model Issue
- Model ch∆∞a h·ªçc t·ªët v·ªõi m·ªôt s·ªë hard samples
- Output saturation ‚Üí uniform predictions
- Loss function c√≥ th·ªÉ kh√¥ng penalize ƒë·ªß m·∫°nh

### 2. Greedy Algorithm Design Flaw
- Kh√¥ng handle **tie-breaking** ƒë√∫ng
- Assumption: `np.where(max)` returns **single index** ‚ùå
- Reality: Returns **all matching indices** khi c√≥ nhi·ªÅu max

---

## Gi·∫£i ph√°p ƒë·ªÅ xu·∫•t

### Option 1: Fix Greedy Algorithm (Recommended)

```python
def avoid_coll_fixed(prednp, param_dict):
    pp = np.zeros((param_dict['N'], param_dict['N']))
    minn = prednp.min()
    prednp_copy = prednp.copy()  # Don't modify original
    
    for elms in range(param_dict['N']):
        # Find max
        max_val = prednp_copy.max()
        r1, c1 = np.where(prednp_copy == max_val)
        
        # FIX: Pick FIRST match only (break tie deterministically)
        r1 = r1[0]
        c1 = c1[0]
        
        # Assign
        pp[r1, c1] = 1
        
        # Remove row and column
        prednp_copy[r1, :] = minn
        prednp_copy[:, c1] = minn
    
    return np.argmax(pp, axis=1)
```

**∆Øu ƒëi·ªÉm:**
- ƒê·∫£m b·∫£o **100% validity**
- Tie-breaking deterministic (ch·ªçn index ƒë·∫ßu ti√™n)
- Simple fix

### Option 2: Use Hungarian Algorithm as Fallback

```python
def avoid_coll_with_fallback(prednp, param_dict):
    result = avoid_coll(prednp, param_dict)
    
    # Check validity
    if len(np.unique(result)) != param_dict['N']:
        # Fallback to Hungarian
        row, col = linear_sum_assignment(-prednp)  # Maximize
        return col
    
    return result
```

**∆Øu ƒëi·ªÉm:**
- Guaranteed optimal solution khi greedy fail
- No modification to greedy logic

**Nh∆∞·ª£c ƒëi·ªÉm:**
- Th√™m overhead (0.38% cases ch·∫°y Hungarian)

### Option 3: Add Noise to Break Ties

```python
def avoid_coll_with_noise(prednp, param_dict):
    # Add small random noise to break ties
    noise = np.random.randn(*prednp.shape) * 1e-6
    prednp_noisy = prednp + noise
    return avoid_coll(prednp_noisy, param_dict)
```

**∆Øu ƒëi·ªÉm:**
- Minimal code change
- Breaks uniform ties

**Nh∆∞·ª£c ƒëi·ªÉm:**
- Non-deterministic
- Might not be theoretically clean

---

## K·∫øt lu·∫≠n

### C√¢u tr·∫£ l·ªùi cho c√¢u h·ªèi ban ƒë·∫ßu:

**"T·∫°i sao c√≥ greedy r·ªìi m√† v·∫´n kh√¥ng ƒë∆∞·ª£c 100% valid?"**

1. **Greedy algorithm c√≥ BUG** khi handle tie-breaking
2. **GNN predict uniform values** trong 0.38% cases
3. Bug manifest khi **T·∫§T C·∫¢ predictions b·∫±ng nhau**
4. `np.where(max)` returns **T·∫§T C·∫¢ indices** ‚Üí g√°n sai

### S·ªë li·ªáu:
- **99.62% valid** - Greedy ho·∫°t ƒë·ªông t·ªët v·ªõi predictions c√≥ variance
- **0.38% fail** - GNN outputs uniform ‚Üí Greedy bug activated
- **75 failures** trong 20,000 samples

### Recommended fix:
S·ª≠a `avoid_coll` ƒë·ªÉ ch·ªâ pick **FIRST match** khi c√≥ tie:
```python
r1, c1 = r1[0], c1[0]  # ‚Üê Add this line
```

ƒêi·ªÅu n√†y ƒë·∫£m b·∫£o **100% validity** v·ªõi minimal code change! üéØ

---

## Testing sau khi fix

```bash
# Test v·ªõi fixed version
python test_greedy_fixed.py

# Expected:
# Valid rate: 100.00% (20,000 / 20,000)
# No failures!
```
