"""
So sÃ¡nh TRá»°C QUAN giá»¯a Success vÃ  Failure case
"""

import numpy as np
import torch
from scipy.optimize import linear_sum_assignment
from networks import HGNN
from helper_fn import get_adj, avoid_coll
from torch_geometric.data import Data

# Load model
param_dict = {'N': 4, 'H': 32, 'K': 1}
model = HGNN(param_dict['N'], param_dict['H'], param_dict['N'])
model.load_state_dict(torch.load('trained_net_paper_setup_final.pth'))
model.eval()

test_data = np.load('data/test_paper_20k.npy')
edge_index = get_adj(param_dict['N'])
N = param_dict['N']

print("="*120)
print("ğŸ” SO SÃNH SUCCESS vs FAILURE CASE")
print("="*120)

cases = [
    (0, "SUCCESS", "âœ…"),
    (214, "FAILURE", "âŒ"),
]

for sample_idx, label, icon in cases:
    print(f"\n{icon} {label} CASE - Sample #{sample_idx}")
    print("-"*120)
    
    cost_matrix = test_data[sample_idx]
    x = torch.from_numpy(np.concatenate((cost_matrix, cost_matrix.T), axis=0)).float()
    G = Data(x, edge_index)
    
    with torch.no_grad():
        output = model(G.x, G.edge_index)
    
    print(f"\nğŸ“‹ Cost Matrix:")
    print(cost_matrix)
    
    print(f"\nğŸ”¥ GNN Output (Raw Logits):")
    print(output.numpy())
    
    print(f"\nğŸ“Š Thá»‘ng kÃª tá»«ng hÃ ng (cÃ´ng nhÃ¢n):")
    print(f"{'':4} {'Min':>8} {'Max':>8} {'Mean':>8} {'Std':>8} {'Interpretation':>30}")
    print("-"*120)
    for i in range(N):
        row = output[i]
        min_val = row.min().item()
        max_val = row.max().item()
        mean_val = row.mean().item()
        std_val = row.std().item()
        
        if std_val > 5:
            interp = "ğŸŸ¢ Ráº¥t tá»± tin"
        elif std_val > 2:
            interp = "ğŸŸ¡ KhÃ¡ cháº¯c cháº¯n"
        else:
            interp = "ğŸ”´ KhÃ´ng cháº¯c"
        
        print(f"CN{i}  {min_val:8.3f} {max_val:8.3f} {mean_val:8.3f} {std_val:8.3f} {interp:>30}")
    
    # Before greedy
    pred_before = torch.argmax(output, dim=1).numpy()
    
    # After greedy
    pred_after = avoid_coll(output.numpy(), param_dict)
    
    # Ground truth
    r_gt, c_gt = linear_sum_assignment(cost_matrix)
    
    print(f"\nğŸ¯ Káº¿t quáº£:")
    print(f"   Before Greedy (argmax): {pred_before}")
    print(f"   After Greedy:           {pred_after}")
    print(f"   Ground Truth:           {c_gt}")
    print(f"   Unique values:          {np.unique(pred_after)} (count: {len(np.unique(pred_after))})")
    
    is_valid = len(np.unique(pred_after)) == N
    is_optimal = np.array_equal(pred_after, c_gt)
    
    print(f"\n   Valid (khÃ´ng trÃ¹ng):    {'âœ… YES' if is_valid else 'âŒ NO'}")
    print(f"   Optimal (tá»‘i Æ°u):       {'âœ… YES' if is_optimal else 'âŒ NO'}")
    
    if not is_valid:
        print(f"\n   ğŸ”¥ LÃ DO THáº¤T Báº I:")
        print(f"   â†’ Sau 3 bÆ°á»›c greedy, táº¥t cáº£ giÃ¡ trá»‹ cÃ²n láº¡i uniform")
        print(f"   â†’ np.where() tráº£ vá» Táº¤T Cáº¢ positions")
        print(f"   â†’ pp matrix trá»Ÿ thÃ nh all 1s")
        print(f"   â†’ argmax(pp) = [0,0,0,0] (invalid!)")

print("\n" + "="*120)
print("ğŸ“š Tá»”NG Káº¾T")
print("="*120)

print("""
SUCCESS CASE (Sample #0):
âœ… Logits cÃ³ variance tá»‘t (Std > 5 cho má»—i hÃ ng)
âœ… Model tá»± tin, lá»±a chá»n rÃµ rÃ ng
âœ… Greedy hoáº¡t Ä‘á»™ng tá»‘t qua cáº£ 4 bÆ°á»›c
âœ… Káº¿t quáº£: Valid + Optimal

FAILURE CASE (Sample #214):
âš ï¸  Logits ban Ä‘áº§u cÃ³ variance (Std > 4)
âš ï¸  NhÆ°ng sau 3 bÆ°á»›c greedy, cÃ²n láº¡i uniform
âŒ Step 4: All remaining = min value
âŒ np.where() returns ALL indices
âŒ Káº¿t quáº£: Invalid (duplicate assignments)

Káº¾T LUáº¬N:
- ÄÃ¢y KHÃ”NG PHáº¢I lá»—i cá»§a GNN model (output ban Ä‘áº§u tá»‘t)
- ÄÃ¢y lÃ  Háº N CHáº¾ cá»§a Greedy Algorithm
- Tá»· lá»‡ tháº¥t báº¡i: 0.38% (ráº¥t hiáº¿m)
- CÃ³ thá»ƒ fix báº±ng cÃ¡ch:
  1. Break ties deterministically
  2. Fallback to Hungarian
  3. Add small random noise
""")

print("="*120)
